{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import pprint as pp\n",
    "\n",
    "# text embeddings\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# keywords extraction\n",
    "import yake\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Universal Sentence Encoder's TF Hub module\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
    "model = hub.load(module_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_search(path, n_keywords=10):\n",
    "    \"\"\"\n",
    "    converts database of filename -> paragraphs to\n",
    "    database keyword -> paragraph -> filename\n",
    "\n",
    "    input:\n",
    "      path        - as string, path to tab delimited file with columns \"file_name\" and \"paragraph\"\n",
    "                    where each paragraph is extracted and saved in a separate cell with corresponding file name\n",
    "                    in the same row\n",
    "      n_keywords  – as integer, number of keywords to extract\n",
    "\n",
    "    output:\n",
    "      pandas data frame, ready for search.\n",
    "    \"\"\"\n",
    "    df_paragraphs = pd.read_csv(path, sep=\"\\t\")\n",
    "\n",
    "    print(\"Extracting keywords...\")\n",
    "    df_paragraphs['keywords'] = df_paragraphs['paragraph'].apply(lambda text: extract_keywords(text,\n",
    "                                                                                               method=method,\n",
    "                                                                                               n_keywords=n_keywords))\n",
    "    print(\"Transforming to a data frame with a keywordd per row...\")\n",
    "    list_dfs = []\n",
    "\n",
    "    for i in range(len(df_paragraphs)):\n",
    "        row = df_paragraphs.iloc[i]\n",
    "        list_of_keywords = row['keywords']\n",
    "        paragraph = row['paragraph']\n",
    "        file_name = row['file_name']\n",
    "\n",
    "        df_k = pd.DataFrame(list_of_keywords, columns=['keyword'])\n",
    "        df_k['paragraph'] = paragraph\n",
    "        df_k['file_name'] = file_name\n",
    "\n",
    "        list_dfs.append(df_k)\n",
    "\n",
    "    df_data = pd.concat(list_dfs)\n",
    "    df_data = df_data[[\"file_name\", \"paragraph\", \"keyword\"]]\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keyphrases(text, n_keywords=10, ngram_range=3):\n",
    "    \"\"\"\n",
    "    Extracts keywords/key/phrases from a text using \"YAKE!\" keyword extraction method\n",
    "\n",
    "    Intuition:https://towardsdatascience.com/keyword-extraction-methods-the-overview-35557350f8bb\n",
    "    Research paper: https://www.sciencedirect.com/science/article/abs/pii/S0020025519308588\n",
    "    Demo: http://yake.inesctec.pt/\n",
    "    Instalation: https://pypi.org/project/yake/\n",
    "\n",
    "    Input:\n",
    "        text        – as string, text of a paragraph to process and extract keywords\n",
    "        n_keywords  – as integer, number of keywords to extract\n",
    "        ngram_range – as integer, maximum number of words in extracted phrase. Default is 3.\n",
    "        \n",
    "    Output:\n",
    "        List of strings – extracted keywords/keyphrases\n",
    "\n",
    "    \"\"\"\n",
    "    list_keywords = []\n",
    "\n",
    "    pyake = yake.KeywordExtractor(lan=\"en\", n=ngram_range)\n",
    "\n",
    "    result = pyake.extract_keywords(text)\n",
    "    result.sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    list_keywords = result[:n_keywords]\n",
    "    list_keywords = [t[0] for t in list_keywords]\n",
    "\n",
    "    return list_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(list_of_strings):\n",
    "    return model(list_of_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting keyphrases\n",
    "**NOTE:**\n",
    "- To make sure Universal Sentence Encoder can work with BILLs wording of the text, I copy-pasted a few paragraphs from 2 bills\n",
    "- Example documents have extracted paragraphs in them tab delimited with bill name (file_name)\n",
    "- For the illustration, last paragraph of the document A is a copy of the first paragraph in document B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"./input_folder/\"\n",
    "\n",
    "doc_A = \"doc1.txt\"\n",
    "doc_B = \"doc2.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BILLS-116hjres31enr</td>\n",
       "      <td>For necessary expenses of U.S. Customs and Bor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BILLS-116hjres31enr</td>\n",
       "      <td>For necessary expenses of U.S. Immigration and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BILLS-116hjres31enr</td>\n",
       "      <td>For necessary expenses of the Coast Guard for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_name                                          paragraph\n",
       "0  BILLS-116hjres31enr  For necessary expenses of U.S. Customs and Bor...\n",
       "1  BILLS-116hjres31enr  For necessary expenses of U.S. Immigration and...\n",
       "2  BILLS-116hjres31enr  For necessary expenses of the Coast Guard for ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_A = pd.read_csv(input_folder + doc_A, \n",
    "                   encoding=\"utf-8\",\n",
    "                   encoding_errors='ignore',\n",
    "                   sep=\"\\t\")\n",
    "df_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BILLS-116s47enr</td>\n",
       "      <td>For necessary expenses of the Coast Guard for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BILLS-116s47enr</td>\n",
       "      <td>Notwithstanding any other provision of law, if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BILLS-116s47enr</td>\n",
       "      <td>The University shall pay all costs associated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BILLS-116s47enr</td>\n",
       "      <td>The Secretary of Agriculture shall permit by s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_name                                          paragraph\n",
       "0  BILLS-116s47enr  For necessary expenses of the Coast Guard for ...\n",
       "1  BILLS-116s47enr  Notwithstanding any other provision of law, if...\n",
       "2  BILLS-116s47enr  The University shall pay all costs associated ...\n",
       "3  BILLS-116s47enr  The Secretary of Agriculture shall permit by s..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_B = pd.read_csv(input_folder + doc_B, \n",
    "                   encoding=\"utf-8\",\n",
    "                   encoding_errors='ignore',\n",
    "                   sep=\"\\t\")\n",
    "df_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The Idea:**\n",
    "Use Universal Sentence Encoder on the string of concatenated key-phrases from each paragraphs to get similarity of the paragraph.\n",
    "This way legislations that work on the same issues will be captured for comparison. Note, details that make the difference myght be lost during such search.\n",
    "\n",
    "\n",
    "**Thoughts behind:**<br>\n",
    "Pretrained Universal Sentence Encoder (USE) is a good choice in comparing short texts (paragraphs).\n",
    "The drawback is that it is based on BERT which is pretrained on general English texts not Legal or Government specific wording. Hence, working with full paragraph can reduce the quality of comparison. Taking just key-phrases reduces confusion of USE around semantic similarity of the paragraphs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting keyphrases for each paragraph:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A['keyphrases'] = df_A['paragraph'].apply(lambda x: extract_keyphrases(x))\n",
    "df_B['keyphrases'] = df_B['paragraph'].apply(lambda x: extract_keyphrases(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT:\n",
      "\n",
      "('For necessary expenses of U.S. Customs and Border Protection for operations '\n",
      " 'and support, including the transportation of unaccompanied minor aliens; the '\n",
      " 'provision of air and marine support to Federal, State, and local agencies in '\n",
      " 'the enforcement or administration of laws enforced by the Department of '\n",
      " 'Homeland Security; at the discretion of the Secretary of Homeland Security, '\n",
      " 'the provision of such support to Federal, State, and local agencies in other '\n",
      " 'law enforcement and emergency humanitarian efforts; the purchase and lease '\n",
      " 'of up to 7,500 (6,500 for replacement only) police-type vehicles; the '\n",
      " 'purchase, maintenance, or operation of marine vessels, aircraft, and '\n",
      " 'unmanned aerial systems; and contracting with individuals for personal '\n",
      " 'services abroad; $12,179,729,000; of which $3,274,000 shall be derived from '\n",
      " 'the Harbor Maintenance Trust Fund for administrative expenses related to the '\n",
      " 'collection of the Harbor Maintenance Fee pursuant tosection 9505(c)(3) of '\n",
      " 'the Internal Revenue Code of 1986 and notwithstanding section 1511(e)(1) of '\n",
      " 'the Homeland Security Act of 2002. ')\n",
      "\n",
      "\n",
      "EXTRACTED KEYPHRASES:\n",
      "\n",
      "['Customs and Border',\n",
      " 'Maintenance Trust',\n",
      " 'Maintenance Fee',\n",
      " 'support to Federal',\n",
      " 'local agencies',\n",
      " 'Security Act',\n",
      " 'Harbor Maintenance',\n",
      " 'administrative expenses related',\n",
      " 'unaccompanied minor aliens',\n",
      " 'emergency humanitarian efforts']\n"
     ]
    }
   ],
   "source": [
    "#Example:\n",
    "index=0\n",
    "\n",
    "text = df_A['paragraph'].iloc[index]\n",
    "keyphrases = df_A['keyphrases'].iloc[index]\n",
    "\n",
    "print(\"TEXT:\\n\")\n",
    "pp.pprint(text)\n",
    "\n",
    "print(\"\\n\\nEXTRACTED KEYPHRASES:\\n\")\n",
    "pp.pprint(keyphrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**concatenating keyphrases in one string separated by whitespace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Customs and Border Maintenance Trust Maintenance Fee support to Federal local agencies Security Act Harbor Maintenance administrative expenses related unaccompanied minor aliens emergency humanitarian efforts'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_A['key_phr_string'] = df_A['keyphrases'].apply(lambda x: \" \".join(x))\n",
    "df_B['key_phr_string'] = df_B['keyphrases'].apply(lambda x: \" \".join(x))\n",
    "df_A['key_phr_string'].iloc[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting USE embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>keyphrases</th>\n",
       "      <th>key_phr_string</th>\n",
       "      <th>e_0</th>\n",
       "      <th>e_1</th>\n",
       "      <th>e_2</th>\n",
       "      <th>e_3</th>\n",
       "      <th>e_4</th>\n",
       "      <th>e_5</th>\n",
       "      <th>...</th>\n",
       "      <th>e_502</th>\n",
       "      <th>e_503</th>\n",
       "      <th>e_504</th>\n",
       "      <th>e_505</th>\n",
       "      <th>e_506</th>\n",
       "      <th>e_507</th>\n",
       "      <th>e_508</th>\n",
       "      <th>e_509</th>\n",
       "      <th>e_510</th>\n",
       "      <th>e_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BILLS-116hjres31enr</td>\n",
       "      <td>For necessary expenses of U.S. Customs and Bor...</td>\n",
       "      <td>[Customs and Border, Maintenance Trust, Mainte...</td>\n",
       "      <td>Customs and Border Maintenance Trust Maintenan...</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>0.040324</td>\n",
       "      <td>-0.115766</td>\n",
       "      <td>0.052774</td>\n",
       "      <td>0.038278</td>\n",
       "      <td>-0.027752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006531</td>\n",
       "      <td>-0.048225</td>\n",
       "      <td>0.083112</td>\n",
       "      <td>0.042204</td>\n",
       "      <td>0.03136</td>\n",
       "      <td>0.052765</td>\n",
       "      <td>0.048066</td>\n",
       "      <td>-0.084458</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.052355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_name                                          paragraph  \\\n",
       "0  BILLS-116hjres31enr  For necessary expenses of U.S. Customs and Bor...   \n",
       "\n",
       "                                          keyphrases  \\\n",
       "0  [Customs and Border, Maintenance Trust, Mainte...   \n",
       "\n",
       "                                      key_phr_string       e_0       e_1  \\\n",
       "0  Customs and Border Maintenance Trust Maintenan... -0.001087  0.040324   \n",
       "\n",
       "        e_2       e_3       e_4       e_5  ...     e_502     e_503     e_504  \\\n",
       "0 -0.115766  0.052774  0.038278 -0.027752  ... -0.006531 -0.048225  0.083112   \n",
       "\n",
       "      e_505    e_506     e_507     e_508     e_509     e_510     e_511  \n",
       "0  0.042204  0.03136  0.052765  0.048066 -0.084458  0.004189  0.052355  \n",
       "\n",
       "[1 rows x 516 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE: using tensors here might be faster and require less memory space\n",
    "e_columns = [\"e_\" + str(i) for i in range(512)]\n",
    "\n",
    "list_of_strings_A = list(df_A['key_phr_string'])\n",
    "embeddings = model(list_of_strings_A).numpy()\n",
    "\n",
    "df_A[e_columns] = embeddings\n",
    "df_A.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>keyphrases</th>\n",
       "      <th>key_phr_string</th>\n",
       "      <th>e_0</th>\n",
       "      <th>e_1</th>\n",
       "      <th>e_2</th>\n",
       "      <th>e_3</th>\n",
       "      <th>e_4</th>\n",
       "      <th>e_5</th>\n",
       "      <th>...</th>\n",
       "      <th>e_502</th>\n",
       "      <th>e_503</th>\n",
       "      <th>e_504</th>\n",
       "      <th>e_505</th>\n",
       "      <th>e_506</th>\n",
       "      <th>e_507</th>\n",
       "      <th>e_508</th>\n",
       "      <th>e_509</th>\n",
       "      <th>e_510</th>\n",
       "      <th>e_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BILLS-116s47enr</td>\n",
       "      <td>For necessary expenses of the Coast Guard for ...</td>\n",
       "      <td>[support including, contingent and emergent, u...</td>\n",
       "      <td>support including contingent and emergent unit...</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>-0.079505</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>-0.011146</td>\n",
       "      <td>-0.009077</td>\n",
       "      <td>0.016665</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038383</td>\n",
       "      <td>-0.015171</td>\n",
       "      <td>0.071899</td>\n",
       "      <td>0.021445</td>\n",
       "      <td>0.03865</td>\n",
       "      <td>0.013235</td>\n",
       "      <td>-0.028723</td>\n",
       "      <td>-0.074453</td>\n",
       "      <td>0.050429</td>\n",
       "      <td>0.020433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_name                                          paragraph  \\\n",
       "0  BILLS-116s47enr  For necessary expenses of the Coast Guard for ...   \n",
       "\n",
       "                                          keyphrases  \\\n",
       "0  [support including, contingent and emergent, u...   \n",
       "\n",
       "                                      key_phr_string       e_0       e_1  \\\n",
       "0  support including contingent and emergent unit...  0.005286 -0.079505   \n",
       "\n",
       "        e_2       e_3       e_4       e_5  ...     e_502     e_503     e_504  \\\n",
       "0  0.008594 -0.011146 -0.009077  0.016665  ... -0.038383 -0.015171  0.071899   \n",
       "\n",
       "      e_505    e_506     e_507     e_508     e_509     e_510     e_511  \n",
       "0  0.021445  0.03865  0.013235 -0.028723 -0.074453  0.050429  0.020433  \n",
       "\n",
       "[1 rows x 516 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE: using tensors here might be faster and require less memory space\n",
    "e_columns = [\"e_\" + str(i) for i in range(512)]\n",
    "\n",
    "list_of_strings_B = list(df_B['key_phr_string'])\n",
    "embeddings = model(list_of_strings_B).numpy()\n",
    "\n",
    "df_B[e_columns] = embeddings\n",
    "df_B.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Doc_A paragraphs, finding most similar paragraph in Doc_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36875415,  0.01394344,  0.13117695,  0.11275332],\n",
       "       [ 0.10659477,  0.02777174, -0.01563178,  0.04973911],\n",
       "       [ 1.0000002 ,  0.0902687 ,  0.26971418,  0.09652793]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix = cosine_similarity(df_A[e_columns].values, df_B[e_columns].values)\n",
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine similarity is bounded in the interval [-1, 1]<br>\n",
    "To make it [0,1], we can replace any values below 0 with 0, since it does not matter how dissimilar paragraphs are.<br><br>\n",
    "**NOTE:** \n",
    "- similarity matrix displays similarity scores between paragraphs in doc_A (rows) with doc_B (columns)\n",
    "- you can experiment with different input data for this notebook before putting this intu module functions\n",
    "\n",
    "**Observations:**\n",
    "- last paragraph of document A was correctly identified to be a copy of first paragraph of doc B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc_A TEXT:\n",
      "('For necessary expenses of U.S. Immigration and Customs Enforcement for '\n",
      " 'operations and support, including the purchase and lease of up to 3,790 '\n",
      " '(2,350 for replacement only) police-type vehicles; overseas vetted units; '\n",
      " 'and maintenance, minor construction, and minor leasehold improvements at '\n",
      " 'owned and leased facilities; $7,542,153,000; of which $6,000,000 shall '\n",
      " 'remain available until expended for efforts to enforce laws against forced '\n",
      " 'child labor; of which $75,448,000 shall remain available until September 30, '\n",
      " '2020; of which $1,500,000 is for paid apprenticeships for participants in '\n",
      " 'the Human Exploitation Rescue Operative Child-Rescue Corps; of which not '\n",
      " 'less than $15,000,000 shall be available for investigation of intellectual '\n",
      " 'property rights violations, including operation of the National Intellectual '\n",
      " 'Property Rights Coordination Center; and of which not less than '\n",
      " '$4,273,857,000 shall be for enforcement, detention, and removal operations, '\n",
      " 'including transportation of unaccompanied minor aliens')\n",
      "\n",
      "\n",
      "Doc_B TEXT:\n",
      "('Notwithstanding any other provision of law, if after the completion of the '\n",
      " 'appraisal required under subsection (c), the University submits to the '\n",
      " 'Secretary an offer to acquire the reversionary interests of the United '\n",
      " 'States in and to the non-Federal land, the Secretary shall convey to the '\n",
      " 'University the reversionary interests of the United States in and to the '\n",
      " 'non-Federal land for the purpose of unencumbering the title to the '\n",
      " 'non-Federal land to enable economic development of the non-Federal land.')\n"
     ]
    }
   ],
   "source": [
    "#printing text of paragraps by indexies in the similarity_matrix\n",
    "row = 1 #doc_A paragraph number\n",
    "column = 1 #doc_A paragraph number\n",
    "\n",
    "print(\"Doc_A TEXT:\")\n",
    "pp.pprint(df_A['paragraph'].iloc[row])\n",
    "print(\"\\n\\nDoc_B TEXT:\")\n",
    "pp.pprint(df_B['paragraph'].iloc[column])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
